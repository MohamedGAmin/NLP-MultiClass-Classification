{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main","provenance":[],"collapsed_sections":[],"mount_file_id":"118xXgLcFzGblFvsLO-mxINzChqqdYgrW","authorship_tag":"ABX9TyODIYKnXURqLqLEBNnZY3uk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kM3RVX2iOtZu"},"source":["# Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56jxybYROpga","executionInfo":{"status":"ok","timestamp":1639346230596,"user_tz":-120,"elapsed":1724,"user":{"displayName":"Mohamed Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYj1A1DI31J9UAHG_y0hvKKp9jwthX27z4wF9=s64","userId":"01008405082416255879"}},"outputId":"55354cad-a30f-481b-853a-eb29db1d5019"},"source":["import pandas as pd\n","import pickle\n","import re\n","import nltk\n","from nltk.stem import *\n","from nltk.stem.porter import *\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"markdown","metadata":{"id":"MaAy_ceUOvG3"},"source":["# Text Preprocessing"]},{"cell_type":"code","metadata":{"id":"2dOBHUN3Oyew"},"source":["\n","REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n","BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n","STOPWORDS = set(stopwords.words('english'))\n","\n","def clean_text(text):\n","    \"\"\"\n","  \n","    \"\"\"\n","    text=str(text)\n","\n","    text=re.sub(r\"\\d\", \"\", text) #remove numbers \n","    text = text.lower() # lowercase text\n","    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n","    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n","    text = text.replace('x', '')\n","#    text = re.sub(r'\\W+', '', text)\n","    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n","    \n","    rmv = ['serial','number','thank','request','dear','hi','is','please','call']\n","    \n","    querywords = text.split()\n","    resultwords  = [word for word in querywords if word.lower() not in rmv] #remove\n","\n","\n","    stemmer = SnowballStemmer(\"english\") \n","    text=[stemmer.stem(word) for word in resultwords]      # stem the words\n","    text = ' '.join(text)\n","    \n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6sCPn__Ozi7"},"source":["def reading(text= \" \",csv=False,subject='SUBJECT',description='DESCRIPTION'):\n","\n","  if csv:\n","    df=pd.read_csv(csv)\n","    df = df.reset_index(drop=True)\n","    df[description] =  df[subject] + \" \" +df[description] # adding subject\n","    df[description] = df[description].apply(clean_text)\n","    df[description] = df[description].str.replace('\\d+', '')\n","    return df[description]\n","\n","  else:\n","    output=str(clean_text(text))\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXuP7rWWOzgV"},"source":["def predict_values(pred,text=False,file=False,filename='output.csv'):\n","  labels = ['General Inquiry', 'Product Support', 'Order Information',\n","       'Training or Login or Website ', 'Software Support',\n","       'Instrument & Hardware', 'Software & Application']\n","\n","  ouput_list=[labels[i] for i in pred]\n","  if text:\n","    print(str(ouput_list))\n","  if file:\n","    df=pd.DataFrame(ouput_list,columns=['label'])\n","\n","    df.to_csv(filename,index=False)\n","    print('file saved')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"meKnXKDSprdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29FoE80wcbfP"},"source":["input_data=reading(csv='data.csv') #input text/ for csv type csv=file path\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mj4VupjfO01Q"},"source":["#Load Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tRAMiIpiO0pw","executionInfo":{"status":"ok","timestamp":1639346392130,"user_tz":-120,"elapsed":866,"user":{"displayName":"Mohamed Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYj1A1DI31J9UAHG_y0hvKKp9jwthX27z4wF9=s64","userId":"01008405082416255879"}},"outputId":"966bea5b-f27b-478f-dbee-870267908661"},"source":["model = pickle.load(open('/content/drive/MyDrive/Freelancing/Multi Class Classification NLP - Ryan Rozario/finalized_ML_LR.sav', 'rb')) "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:333: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:333: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:333: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:333: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n"]}]},{"cell_type":"markdown","metadata":{"id":"choMpAhwZ8id"},"source":["#Predict"]},{"cell_type":"code","metadata":{"id":"4988cTRTPaui"},"source":["if type(input_data) == str:\n","  input_data=[str(input_data)]\n","\n","pred= model.predict(input_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2M5IvuOn0us","executionInfo":{"status":"ok","timestamp":1639346395794,"user_tz":-120,"elapsed":8,"user":{"displayName":"Mohamed Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYj1A1DI31J9UAHG_y0hvKKp9jwthX27z4wF9=s64","userId":"01008405082416255879"}},"outputId":"48bbb24f-5ccf-42ef-ec77-7a4ef303f7e2"},"source":["predict_values(pred,file=True) # change the parameters according to your needs"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["file saved\n"]}]},{"cell_type":"code","metadata":{"id":"PWfy-a3tl1CT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CV5YQETpNppz"},"source":[""],"execution_count":null,"outputs":[]}]}